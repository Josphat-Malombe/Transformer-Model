{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753695d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilingualDataset(Dataset):\n",
    "    def __init__(self,ds,tokenizer_src,tokenizer_tgt,src_lang,tgt_lang,seq_len)->None:\n",
    "        super().__init__()\n",
    "        self.ds=ds\n",
    "        self.tokenizer_src=tokenizer_src\n",
    "        self.tokenizer_tgt=tokenizer_tgt\n",
    "        self.src_lang=src_lang\n",
    "        self.tgt_lang=tgt_lang\n",
    "\n",
    "        self.sos_token=torch.Tensor([tokenizer_src.token_to_id(['[SOS]'])],dtype=torch.int64)\n",
    "        self.eos_token=torch.Tensor([tokenizer_src.token_to_id(['[EOS]'])],dtype=torch.int64)\n",
    "        self.pad_token=torch.Tensor([tokenizer_src.token_to_id(['[PAD]'])],dtype=torch.int64)\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        src_target_pair=self.ds[index]\n",
    "\n",
    "        src_text=src_target_pair['translation'][self.src_lang]\n",
    "        tgt_text=src_target_pair['translation'][self.tgt_lang]\n",
    "\n",
    "        enc_input_tokens=self.tokenizer_src.encode(src_text).ids\n",
    "        dec_input_tokens=self.tokenizer_tgt.encode(tgt_text).ids\n",
    "\n",
    "        enc_num_padding_tokens=self.seq_len - len(enc_input_tokens) -2\n",
    "        dec_num_padding_token=self.seq_len-len(dec_input_tokens)-1\n",
    "\n",
    "        if enc_num_padding_tokens<0 or dec_num_padding_token<0:\n",
    "            raise ValueError(\"Sentence is too long\")\n",
    "        \n",
    "        encoder_input=torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(enc_input_tokens,dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] * enc_num_padding_tokens ,dtype=torch.int64)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        decoder_input=torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token])\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        label=torch.cat(\n",
    "            [\n",
    "                torch.tensor(dec_input_tokens,dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] *dec_num_padding_token, dtype=torch.int64)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return{\n",
    "            \"encoder_input\":encoder_input,\n",
    "            \"decoder_input\":decoder_input,\n",
    "            \"encoder_mask\":(encoder_input!=self.pad_token).unsqueeze(0).int(),\n",
    "            \"decoder_mask\":(decoder_input!=self.pad_token).unsqueeze(0).int() & causual_mask(decoder_input.size(0)),\n",
    "            \"label\":label,\n",
    "            \"src_text\":src_text,\n",
    "            \"tgt_text\":tgt_text\n",
    "        }\n",
    "    \n",
    "\n",
    "def causual_mask(size):\n",
    "    mask=torch.triu(torch.ones(1,size,size),diagonal=1).type(torch.int)\n",
    "    return mask==0\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
